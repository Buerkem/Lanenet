{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8467dcf6"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
        "from tensorflow.keras.layers import Add\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from tensorflow.keras.layers import Activation, Input\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import BatchNormalization, Concatenate\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Softmax, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import skimage\n",
        "from skimage.io import imread"
      ],
      "id": "8467dcf6"
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURE_DIM = 4\n",
        "delta_v = 0.5\n",
        "delta_d = 0.5\n",
        "param_var = 0.5\n",
        "param_dist = 0.5\n",
        "param_reg = 0.5\n",
        "num_images = 4\n",
        "data_path = \"./data/image\"\n",
        "label_path = \"./data/gt_binary_image\""
      ],
      "metadata": {
        "id": "tL1hQ1imulGM"
      },
      "id": "tL1hQ1imulGM",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d81d6f94"
      },
      "outputs": [],
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    Arguments:\n",
        "        inputs (tensor): Input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): Activation name\n",
        "        batch_normalization (bool): Whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    Returns:\n",
        "        x (tensor): Tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "id": "d81d6f94"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4e096c02"
      },
      "outputs": [],
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): Shape of input image tensor\n",
        "        depth (int): Number of core convolutional layers\n",
        "        num_classes (int): Number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = Add()([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # feature maps\n",
        "    outputs = features_pyramid(x, n_layers)\n",
        "    \n",
        "\n",
        "    # instantiate model\n",
        "    name = 'ResNet%dv1' % (depth)\n",
        "    model = Model(inputs=inputs,\n",
        "                  outputs=outputs,\n",
        "                  name=name)\n",
        "    return model"
      ],
      "id": "4e096c02"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "20a8cbb3"
      },
      "outputs": [],
      "source": [
        "def resnet_v2(input_shape, depth, n_layers=4):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): Shape of input image tensor\n",
        "        depth (int): Number of core convolutional layers\n",
        "        num_classes (int): Number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = Add()([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    # 1st feature map layer\n",
        "\n",
        "    # main feature maps (160, 120)\n",
        "    # succeeding feature maps are scaled down by\n",
        "    # 2, 4, 8\n",
        "    outputs = features_pyramid(x, n_layers)\n",
        "\n",
        "    # instantiate model.\n",
        "    name = 'ResNet%dv2' % (depth)\n",
        "    model = Model(inputs=inputs,\n",
        "                  outputs=outputs,\n",
        "                  name=name)\n",
        "    return model"
      ],
      "id": "20a8cbb3"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1a2f7765"
      },
      "outputs": [],
      "source": [
        "def features_pyramid(x, n_layers):\n",
        "    \"\"\"Generate features pyramid from the output of the \n",
        "    last layer of a backbone network (e.g. ResNetv1 or v2)\n",
        "\n",
        "    Arguments:\n",
        "        x (tensor): Output feature maps of a backbone network\n",
        "        n_layers (int): Number of additional pyramid layers\n",
        "\n",
        "    Return:\n",
        "        outputs (list): Features pyramid \n",
        "    \"\"\"\n",
        "    outputs = [x]\n",
        "    conv = AveragePooling2D(pool_size=2, name='pool1')(x)\n",
        "    outputs.append(conv)\n",
        "    prev_conv = conv\n",
        "    n_filters = 512\n",
        "\n",
        "    # additional feature map layers\n",
        "    for i in range(n_layers - 1):\n",
        "        postfix = \"_layer\" + str(i+2)\n",
        "        conv = conv_layer(prev_conv,\n",
        "                          n_filters,\n",
        "                          kernel_size=3,\n",
        "                          strides=2,\n",
        "                          use_maxpool=False,\n",
        "                          postfix=postfix)\n",
        "        outputs.append(conv)\n",
        "        prev_conv = conv\n",
        "\n",
        "    return outputs"
      ],
      "id": "1a2f7765"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5002d251"
      },
      "outputs": [],
      "source": [
        "def build_resnet(input_shape,\n",
        "                 n_layers=4,\n",
        "                 version=2,\n",
        "                 n=6):\n",
        "    \"\"\"Build a resnet as backbone\n",
        "\n",
        "    # Arguments:\n",
        "        input_shape (list): Input image size and channels\n",
        "        n_layers (int): Number of feature layers \n",
        "        version (int): Supports ResNetv1 and v2 but v2 by default\n",
        "        n (int): Determines number of ResNet layers\n",
        "                 (Default is ResNet50)\n",
        "\n",
        "    # Returns\n",
        "        model (Keras Model)\n",
        "\n",
        "    \"\"\"\n",
        "    # computed depth from supplied model parameter n\n",
        "    if version == 1:\n",
        "        depth = n * 6 + 2\n",
        "    elif version == 2:\n",
        "        depth = n * 9 + 2\n",
        "\n",
        "    # model name, depth and version\n",
        "    # input_shape (h, w, 3)\n",
        "    if version==1:\n",
        "        model = resnet_v1(input_shape=input_shape,\n",
        "                          depth=depth,\n",
        "                          n_layers=n_layers)\n",
        "    else:\n",
        "        model = resnet_v2(input_shape=input_shape,\n",
        "                          depth=depth,\n",
        "                          n_layers=n_layers)\n",
        "    return model"
      ],
      "id": "5002d251"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "48f2c2a4"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def data_generation(keys, data_path, label_path):\n",
        "    \"\"\"Generate train data: images and \n",
        "    segmentation ground truth labels \n",
        "\n",
        "    Arguments:\n",
        "        keys (array): Randomly sampled keys\n",
        "            (key is image filename)\n",
        "\n",
        "    Returns:\n",
        "        x (tensor): Batch of images\n",
        "        y (tensor): Batch of pixel-wise categories\n",
        "    \"\"\"\n",
        "    # a batch of images\n",
        "    x = []\n",
        "    # and their corresponding segmentation masks\n",
        "    y = []\n",
        "\n",
        "    for i, key in enumerate(keys):\n",
        "        # images are assumed to be stored \n",
        "        # in self.args.data_path\n",
        "        # key is the image filename \n",
        "        image_path = os.path.join(data_path, key)\n",
        "       # print('image_path: ', image_path)\n",
        "        # load the image using OpenCV\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "        # resize the image to (640, 480)\n",
        "        #print(image)\n",
        "        image = cv2.resize(image, (640, 480), interpolation=cv2.INTER_LINEAR)\n",
        "        # convert the image from BGR to RGB format\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        # append image to the list\n",
        "        x.append(image)\n",
        "        # and its corresponding label (segmentation mask)\n",
        "       # print('label_path: ', label_path)\n",
        "        label = os.path.join(label_path, key)\n",
        "        label = skimage.img_as_float(imread(label))\n",
        "        # resize the label to (640, 480)\n",
        "        label = cv2.resize(label, (640, 480), interpolation=cv2.INTER_NEAREST)\n",
        "        y.append(label)\n",
        "\n",
        "    return np.array(x), np.array(y)"
      ],
      "id": "48f2c2a4"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "93abef89"
      },
      "outputs": [],
      "source": [
        "def conv_layer(inputs,\n",
        "               filters=32,\n",
        "               kernel_size=3,\n",
        "               strides=1,\n",
        "               use_maxpool=True,\n",
        "               postfix=None,\n",
        "               activation=None):\n",
        "    \"\"\"Helper function to build Conv2D-BN-ReLU layer\n",
        "        with optional MaxPooling2D.\n",
        "    \"\"\"\n",
        "\n",
        "    x = Conv2D(filters=filters,\n",
        "               kernel_size=kernel_size,\n",
        "               strides=strides,\n",
        "               kernel_initializer='he_normal',\n",
        "               name=\"conv_\"+postfix,\n",
        "               padding='same')(inputs)\n",
        "    x = BatchNormalization(name=\"bn_\"+postfix)(x)\n",
        "    x = Activation('relu', name='relu_'+postfix)(x)\n",
        "    if use_maxpool:\n",
        "        x = MaxPooling2D(name='pool'+postfix)(x)\n",
        "    return x"
      ],
      "id": "93abef89"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2dd160f4"
      },
      "outputs": [],
      "source": [
        "def tconv_layer(inputs,\n",
        "                filters=32,\n",
        "                kernel_size=3,\n",
        "                strides=2,\n",
        "                postfix=None):\n",
        "    \"\"\"Helper function to build Conv2DTranspose-BN-ReLU \n",
        "        layer\n",
        "    \"\"\"\n",
        "    x = Conv2DTranspose(filters=filters,\n",
        "                        kernel_size=kernel_size,\n",
        "                        strides=strides,\n",
        "                        padding='same',\n",
        "                        kernel_initializer='he_normal',\n",
        "                        name='tconv_'+postfix)(inputs)\n",
        "    x = BatchNormalization(name=\"bn_\"+postfix)(x)\n",
        "    x = Activation('relu', name='relu_'+postfix)(x)\n",
        "    return x"
      ],
      "id": "2dd160f4"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "609d0456"
      },
      "outputs": [],
      "source": [
        "#close enough backbone\n",
        "def build_fcn(input_shape, backbone):\n",
        "    \"\"\"Helper function to build an FCN model.\n",
        "\n",
        "    Arguments:\n",
        "        backbone (Model): A backbone network\n",
        "            such as ResNetv2 or v1\n",
        "        n_classes (int): Number of object classes\n",
        "            including background.\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    features = backbone(inputs)\n",
        "\n",
        "    main_feature = features[0]\n",
        "    features = features[1:]\n",
        "    out_features = [main_feature]\n",
        "    feature_size = 8\n",
        "    size = 2\n",
        "    N = 4\n",
        "    # other half of the features pyramid\n",
        "    # including upsampling or downsampling to resize the\n",
        "    # feature maps to the dimensions\n",
        "    # equal to 1/4 the image size\n",
        "    for feature in features:\n",
        "        postfix = \"fcn_\" + str(feature_size)\n",
        "        feature = conv_layer(feature,\n",
        "                             filters=256,\n",
        "                             use_maxpool=False,\n",
        "                             postfix=postfix)\n",
        "        postfix = postfix + \"_up2d\"\n",
        "        if feature.shape[1] != main_feature.shape[1]:\n",
        "            feature = UpSampling2D(size=(main_feature.shape[1] // feature.shape[1], main_feature.shape[2] // feature.shape[2]),\n",
        "                               interpolation='bilinear',\n",
        "                               name=postfix)(feature)\n",
        "        else:\n",
        "            feature = Conv2D(256, kernel_size=3, strides=1, padding=\"same\", name=postfix)(feature)\n",
        "        out_features.append(feature)\n",
        "        size = size * 2\n",
        "        feature_size = feature_size * 2\n",
        "    \n",
        "    #out_features = out_features[:-2] \n",
        "    #print(out_features)\n",
        "    # concatenate all upsampled features\n",
        "    # concatenate all upsampled features\n",
        "    x = Concatenate()(out_features)\n",
        "    y = tf.identity(x)\n",
        "    # binary segmentation branch\n",
        "    # perform 2 additional feature extraction \n",
        "    # and upsampling\n",
        "    x = tconv_layer(x, 256, postfix=\"up_x2\")\n",
        "    x = tconv_layer(x, 256, postfix=\"up_x4\")\n",
        "\n",
        "    # generate the pixel-wise classifier\n",
        "    x = Conv2DTranspose(filters=1,\n",
        "                    kernel_size=1,\n",
        "                    strides=1,\n",
        "                    padding='same',\n",
        "                    kernel_initializer='he_normal',\n",
        "                    name=\"pre_activation_x\")(x)\n",
        "    x = Activation('sigmoid', name=\"classification_x\")(x)\n",
        "\n",
        "    #instance segmentation branch\n",
        "    y = tconv_layer(y, 256, postfix=\"up_y2\")\n",
        "    y = tconv_layer(y, 256, postfix=\"up_y4\")\n",
        "    \n",
        "    y = Conv2DTranspose(filters=FEATURE_DIM,\n",
        "                    kernel_size=1,\n",
        "                    strides=1,\n",
        "                    padding='same',\n",
        "                    kernel_initializer='he_normal',\n",
        "                    name=\"pre_activation_y\")(y)\n",
        "    y = Activation('sigmoid', name=\"classification_y\")(y)\n",
        "    #y = tf.round(y)\n",
        "    #y = tf.cast(y, tf.int32)\n",
        "\n",
        "\n",
        "    #product\n",
        "    #z = tf.multiply(x, y)\n",
        "\n",
        "    #model = Model(inputs, z, name=\"fcn\")\n",
        "    model = Model(inputs, (x,y), name=\"fcn\")\n",
        "\n",
        "    return model   "
      ],
      "id": "609d0456"
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_loss(binary_seg_logits, binary_label):\n",
        "    binary_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=binary_seg_logits, labels=binary_label))\n",
        "    return binary_loss"
      ],
      "metadata": {
        "id": "goyRvnqRmRkO"
      },
      "id": "goyRvnqRmRkO",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lanenet_loss(correct_label, instance_seg_logits):\n",
        "    _, rows, cols = np.shape(correct_label)\n",
        "    \n",
        "    correct_label = tf.reshape(correct_label, [-1])\n",
        "    instance_seg_logits = tf.reshape(instance_seg_logits, (-1, 4))\n",
        "\n",
        "    # Get the unique values and their counts\n",
        "    unique_labels, unique_id, counts = tf.unique_with_counts(tf.reshape(correct_label, [-1]))\n",
        "    segmented_sum = tf.math.unsorted_segment_sum(instance_seg_logits, correct_label, FEATURE_DIM)\n",
        "    #tf.print(segmented_sum)\n",
        "    counts = tf.cast(counts, tf.float32)\n",
        "\n",
        "    num_instances = tf.size(unique_labels)\n",
        "    mu = tf.math.divide(segmented_sum, tf.reshape(counts, (-1,1)))\n",
        "    mu_expand = tf.gather(mu, unique_id)\n",
        "\n",
        "    instance_seg_logits = tf.cast(instance_seg_logits, tf.float32)\n",
        "    distance = tf.norm(tf.subtract(mu_expand, instance_seg_logits), axis=1, ord=1)\n",
        "    distance = tf.subtract(distance, delta_v)\n",
        "    distance = tf.clip_by_value(distance, 0., distance)\n",
        "    distance = tf.square(distance)\n",
        "\n",
        "    l_var = tf.math.unsorted_segment_sum(distance, unique_id, num_instances)\n",
        "    l_var = tf.math.divide(l_var, counts)\n",
        "    l_var = tf.math.reduce_sum(l_var)\n",
        "    l_var = tf.math.divide(l_var, tf.cast(num_instances, tf.float32))\n",
        "\n",
        "    mu_interleaved_rep = tf.tile(mu, [num_instances, 1])\n",
        "    mu_band_rep = tf.tile(mu, [1, num_instances])\n",
        "    mu_band_rep = tf.reshape(mu_band_rep,(num_instances * num_instances, FEATURE_DIM))\n",
        "\n",
        "    mu_diff = tf.math.subtract(mu_band_rep, mu_interleaved_rep)\n",
        "\n",
        "    intermediate_tensor = tf.math.reduce_sum(tf.math.abs(mu_diff), axis=1)\n",
        "    zero_vector = tf.zeros((1,), dtype=tf.float32)\n",
        "    bool_mask = tf.math.not_equal(intermediate_tensor, zero_vector)\n",
        "    mu_diff_bool = tf.boolean_mask(mu_diff, bool_mask)\n",
        "\n",
        "    mu_norm = tf.norm(mu_diff_bool, axis=1, ord=1)\n",
        "    mu_norm = tf.math.subtract(2. * delta_d, mu_norm)\n",
        "    mu_norm = tf.clip_by_value(mu_norm, 0., mu_norm)\n",
        "    mu_norm = tf.math.square(mu_norm)\n",
        "\n",
        "    l_dist = tf.math.reduce_mean(mu_norm)\n",
        "\n",
        "    l_reg = tf.reduce_mean(tf.norm(mu, axis=1, ord=1))\n",
        "\n",
        "    param_scale = 1.\n",
        "    l_var = param_var * l_var\n",
        "    l_dist = param_dist * l_dist\n",
        "    l_reg = param_reg * l_reg\n",
        "\n",
        "    loss = param_scale * (l_var + l_dist + l_reg)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "EgYmV09HpwgL"
      },
      "id": "EgYmV09HpwgL",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "31a74ab6",
        "outputId": "2d0e9f36-6b13-45bd-f5f0-5b579504af46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train label shape:  (4, 480, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 194s 40s/step - loss: 3.1970 - classification_x_loss: 0.6974 - classification_y_loss: 1.3739\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-59e83dd8cde6>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "image_names = keys = [\"000\"+str(i)+\".png\" for i in range(num_images)]\n",
        "train_data, train_label = data_generation(keys, data_path, label_path)\n",
        "\n",
        "print(\"train label shape: \", train_label.shape)\n",
        "# Define the image shape\n",
        "image_shape = (480, 640)\n",
        "\n",
        "# Create an empty numpy array to store the images\n",
        "images = np.empty((num_images, *image_shape), dtype=np.int32)\n",
        "\n",
        "# Fill in the numpy array with random integer values between 0 and 4\n",
        "for i in range(num_images):\n",
        "    images[i] = np.random.randint(0, FEATURE_DIM, size=image_shape, dtype=np.int32)\n",
        "\n",
        "# Build the model\n",
        "input_shape = train_data[0].shape\n",
        "backbone = build_resnet(input_shape, n_layers=2, version=2, n=6)\n",
        "model = build_fcn(input_shape, backbone)\n",
        "#model.summary()\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(lr=1e-4)\n",
        "#binary_label = train_label  # replace with actual binary label\n",
        "#instance_label = train_label  # replace with actual instance label\n",
        "model.compile(optimizer=optimizer, loss=[binary_loss,lanenet_loss])\n",
        "\n",
        "#print(\"images: \", np.shape(images))\n",
        "# Train the model\n",
        "batch_size = 1\n",
        "epochs = 10\n",
        "history = model.fit(train_data, (train_label, images), batch_size=batch_size, epochs=epochs)"
      ],
      "id": "31a74ab6"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}